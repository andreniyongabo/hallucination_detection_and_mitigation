{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/guw/.conda/envs/gshard/bin/python\n",
      "['/private/home/costajussa/interpretability/transformer-contributions-nmt', '/private/home/guw/.conda/envs/gshard/lib/python38.zip', '/private/home/guw/.conda/envs/gshard/lib/python3.8', '/private/home/guw/.conda/envs/gshard/lib/python3.8/lib-dynload', '', '/private/home/guw/.conda/envs/gshard/lib/python3.8/site-packages', '/private/home/guw/github/dynalab', '/private/home/guw/github/gshard', '/private/home/guw/github/submitit']\n",
      "['/private/home/guw/github/gshard/fairseq']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path = [x for x in sys.path if x !='/private/home/costajussa/.local/lib/python3.8/site-packages' ]\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from fairseq_transformer_wrapper import FairseqTransformerHub, parse_single_alignment\n",
    "\n",
    "import alignment.align as align\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fairseq\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('WARNING')\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.path)\n",
    "print(fairseq.__path__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#europarl_dir = Path(os.environ['EUROPARL_DATA_DIR'])\n",
    "#ckpt_dir = Path(os.environ['EUROPARL_CKPT_DIR'])\n",
    "#iwslt14_dir = Path(os.environ['IWSLT14_DATA_DIR'])\n",
    "#ckpt_dir = Path(os.environ['IWSLT14_CKPT_DIR'])\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "model_type = 'baseline'\n",
    "suffix = '/large_experiments/nllb/mmt/h2_21_models/flores125_v3.3/en_to_many_to_en/v3.3_dense_hrft004.mfp16.mu100000.uf4.lss.enttgt.tmp1.0.shem.NBF.warmup8000.lr0.004.drop0.0.maxtok2560.seed2.valevery200000.max_pos512.adam16bit.fully_sharded.det.transformer.ELS24.DLS24.encffnx8192.decffnx8192.E1024.H16.ATTDRP0.1.RELDRP0.0.ngpu128/checkpoint_15_100000_consolidated' #'_q_wandb'\n",
    "seed = 2253                  # 1234\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    suffix=''\n",
    "ckpt_dir = \"/large_experiments/nllb/mmt/h2_21_models/flores125_v3.3/en_to_many_to_en/v3.3_dense_hrft004.mfp16.mu100000.uf4.lss.enttgt.tmp1.0.shem.NBF.warmup8000.lr0.004.drop0.0.maxtok2560.seed2.valevery200000.max_pos512.adam16bit.fully_sharded.det.transformer.ELS24.DLS24.encffnx8192.decffnx8192.E1024.H16.ATTDRP0.1.RELDRP0.0.ngpu128/\"\n",
    "hub = FairseqTransformerHub.from_pretrained(\n",
    "    ckpt_dir ,\n",
    "    checkpoint_file=\"checkpoint_15_100000_consolidated.pt\",\n",
    "    #data_name_or_path=(europarl_dir / \"processed_data/fairseq_preprocessed_data\").as_posix(), # processed data\n",
    "    data_name_or_path=\"/large_experiments/nllb/mmt/multilingual_bin/flores125.en_xx_en.v3.3/data_bin/shard000/\", # processed data\n",
    "    #(data_name_or_path=iwslt14_dir / \"data-bin\").as_posix(),\n",
    ")\n",
    "num_layers = 6\n",
    "eos_id = hub.tgt_dict.index(\"</s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TranslationMultiSimpleEpochTask' object has no attribute 'src_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Get sample from provided test data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m### IWSLT14 test\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m#test_de_bpe = iwslt14_dir / \"test.de\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#test_de_word = iwslt14_dir / \"tmp/test.de\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m#test_en_bpe = iwslt14_dir / \"test.en\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=5'>6</a>\u001b[0m \u001b[39m#test_en_word = iwslt14_dir / \"tmp/test.en\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=7'>8</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m148\u001b[39m \u001b[39m# 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m src_sent, src_tok, src_tensor, tgt_sent, tgt_tok, tgt_tensor \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mget_sample(\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, i)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSource sentence: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00msrc_sent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTarget sentence: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mtgt_sent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py:57\u001b[0m, in \u001b[0;36mFairseqTransformerHub.get_sample\u001b[0;34m(self, split, index)\u001b[0m\n\u001b[1;32m     <a href='file:///private/home/costajussa/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=53'>54</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mload_dataset(split)\n\u001b[1;32m     <a href='file:///private/home/costajussa/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=55'>56</a>\u001b[0m src_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mdataset(split)[index][\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='file:///private/home/costajussa/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=56'>57</a>\u001b[0m src_tok \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(src_tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49msrc_dict)\n\u001b[1;32m     <a href='file:///private/home/costajussa/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=57'>58</a>\u001b[0m src_sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(src_tensor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39msrc_dict, as_string\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='file:///private/home/costajussa/interpretability/transformer-contributions-nmt/fairseq_transformer_wrapper.py?line=59'>60</a>\u001b[0m tgt_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mdataset(split)[index][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TranslationMultiSimpleEpochTask' object has no attribute 'src_dict'"
     ]
    }
   ],
   "source": [
    "# Get sample from provided test data\n",
    "### IWSLT14 test\n",
    "#test_de_bpe = iwslt14_dir / \"test.de\"\n",
    "#test_de_word = iwslt14_dir / \"tmp/test.de\"\n",
    "#test_en_bpe = iwslt14_dir / \"test.en\"\n",
    "#test_en_word = iwslt14_dir / \"tmp/test.en\"\n",
    "\n",
    "i = 148 # 0, 1 28, 45, 148 (pred_tok vs tgt_tok), 178, 16 (Hallucination)\n",
    "\n",
    "src_sent, src_tok, src_tensor, tgt_sent, tgt_tok, tgt_tensor = hub.get_sample('test', i)\n",
    "print(f\"\\nSource sentence: \\t {src_sent}\")\n",
    "print(f\"Target sentence: \\t {tgt_sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample from Gold alignment dataset\n",
    "#test_de_bpe = europarl_dir / \"processed_data/test.bpe.de\"\n",
    "#test_de_word =  europarl_dir / \"processed_data/test.de\"\n",
    "#test_en_bpe = europarl_dir / \"processed_data/test.bpe.en\"\n",
    "#test_en_word = europarl_dir / \"processed_data/test.en\"\n",
    "#gold_alignment = europarl_dir / \"gold_alignment/alignment.talp\"\n",
    "\n",
    "with open(test_de_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    # BPE source sentences\n",
    "    src_bpe_sents = fbpe.readlines()\n",
    "with open(test_en_bpe, encoding=\"utf-8\") as fbpe:\n",
    "    # BPE target sentences\n",
    "    tgt_bpe_sents = fbpe.readlines()\n",
    "with open(europarl_dir / \"data_in_progress/test.uc.de\", encoding=\"utf-8\") as fword:\n",
    "    # Original source sentences\n",
    "    src_word_sents = fword.readlines()\n",
    "with open(europarl_dir / \"data_in_progress/test.uc.en\", encoding=\"utf-8\") as fword:\n",
    "    # Original target sentences\n",
    "    tgt_word_sents = fword.readlines()\n",
    "\n",
    "# index in dataset\n",
    "i = 3 # index in dataset\n",
    "# 3, 100, 105\n",
    "src_word_sent = src_word_sents[i]\n",
    "print(src_word_sent)\n",
    "tgt_word_sent = tgt_word_sents[i]\n",
    "print(tgt_word_sent)\n",
    "\n",
    "src_tok_str = src_bpe_sents[i].strip() # removes leading and trailing whitespaces\n",
    "src_tok = src_tok_str.split()\n",
    "\n",
    "tgt_tok_str = tgt_bpe_sents[i].strip() # removes leading and trailing whitespaces\n",
    "tgt_tok = tgt_tok_str.split()\n",
    "src_tensor = torch.tensor([hub.src_dict.index(t) for t in src_tok_str.split()] + [eos_id])\n",
    "tgt_tensor = torch.tensor([hub.tgt_dict.index(t) for t in tgt_tok_str.split()] + [eos_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m model_output, log_probs, encoder_out, layer_inputs, layer_outputs \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mtrace_forward(src_tensor, tgt_tensor)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000007vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mGREEDY DECODING\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/costajussa/interpretability/transformer-contributions-nmt/nmt_interpretability.ipynb#ch0000007vscode-remote?line=3'>4</a>\u001b[0m pred_log_probs, pred_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(log_probs, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "model_output, log_probs, encoder_out, layer_inputs, layer_outputs = hub.trace_forward(src_tensor, tgt_tensor)\n",
    "\n",
    "print(\"\\n\\nGREEDY DECODING\\n\")\n",
    "pred_log_probs, pred_tensor = torch.max(log_probs, dim=-1)\n",
    "pred_tok = hub.decode(pred_tensor, hub.task.tgt_dict)\n",
    "pred_sent = hub.decode(pred_tensor, hub.task.tgt_dict, as_string=True)\n",
    "print(f\"Predicted sentence: \\t {pred_sent}\")\n",
    "\n",
    "print(\"\\n\\nBEAM SEARCH\\n\")\n",
    "for pred in hub.generate(src_tensor, 5):\n",
    "    pred_sent = hub.decode(pred['tokens'], hub.task.tgt_dict, as_string=True)\n",
    "    score = pred['score'].item()\n",
    "    print(f\"{score} \\t {pred_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(log_probs, dim=-1)\n",
    "print('probs',probs.size())\n",
    "pred_ind = torch.argmax(probs,dim=-1)\n",
    "print(pred_ind.size())\n",
    "pred = torch.max(probs,dim=-1)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise Analaysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-attention\n",
    "\n",
    "The output of the encoder is considered as input.\n",
    "We add the residual connection contribution as RES (blue residual in Figure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![enc_dec](./img/enc_dec.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "\n",
    "cross_attn_contributions = torch.squeeze(hub.get_contributions(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['decoder.encoder_attn'])#encoder.self_attn\n",
    "cross_attn_contributions = cross_attn_contributions.detach().cpu().numpy()\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "df = pd.DataFrame(cross_attn_contributions[layer],columns=src_tok + ['<EOS>'] + ['RES'],index=pred_tok + ['<EOS>'])\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True)\n",
    "print('mean residual',df['RES'].mean(), 'std', df['RES'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention decoder per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "self_attn_dec_contributions = torch.squeeze(hub.get_contributions(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['decoder.self_attn'])#encoder.self_attn\n",
    "print(self_attn_dec_contributions.size())\n",
    "plt.figure(figsize=(8,8))\n",
    "self_attn_dec_contributions = self_attn_dec_contributions.detach().cpu().numpy()\n",
    "df = pd.DataFrame(self_attn_dec_contributions[layer],columns= ['<EOS>'] + pred_tok, index=pred_tok + ['<EOS>'])\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross + self-attention per layer\n",
    "\n",
    "We multiply the contributions of the decoder self-attention by the value of RES, and concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 3\n",
    "self_dec_contributions = torch.squeeze(hub.get_contributions(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['decoder.self_attn'])#encoder.self_attn\n",
    "cross_contributions = torch.squeeze(hub.get_contributions(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['decoder.encoder_attn'])#encoder.self_attn\n",
    "cross_contributions_layer = cross_contributions[layer]\n",
    "\n",
    "self_dec_contributions_layer = (self_dec_contributions[layer].transpose(0,1)*cross_contributions_layer[:,-1]).transpose(0,1)\n",
    "cross_contributions_layer = cross_contributions_layer[:,:-1]\n",
    "final_cross_contributions = torch.cat((cross_contributions_layer,self_dec_contributions_layer),dim=1)\n",
    "final_cross_contributions_np = final_cross_contributions.detach().cpu().numpy()\n",
    "plt.figure(figsize=(18,9))\n",
    "df = pd.DataFrame(final_cross_contributions_np, columns = src_tok + ['<EOS>'] + ['<BOS>'] + pred_tok, index = pred_tok + ['<EOS>'])\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout of the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevances_enc_self_attn = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['encoder.self_attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder self-attention relevances in last layer (full encoder rollout)\n",
    "plt.figure(figsize=(8,8))\n",
    "df = pd.DataFrame(relevances_enc_self_attn[-1].cpu().detach().numpy(),columns=src_tok + ['<EOS>'], index=src_tok + ['<EOS>'])\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True)\n",
    "plt.gcf().subplots_adjust(bottom=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout of the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rollout = hub.get_contribution_rollout(src_tensor, tgt_tensor, 'l1', norm_mode='min_sum')['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "for layer in range(0,num_layers):\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 20))\n",
    "    gs = GridSpec(3, 4)\n",
    "    gs.update(wspace=1.2, hspace=0.05)#0.015\n",
    "    ax_main = plt.subplot(gs[0:3, :3])\n",
    "    ax_yDist = plt.subplot(gs[1, 3])#, sharey=ax_main)\n",
    "    \n",
    "    contributions_rollout_layer = total_rollout[layer]\n",
    "    contributions_rollout_layer_np = contributions_rollout_layer.detach().cpu().numpy()\n",
    "    df = pd.DataFrame(contributions_rollout_layer_np, columns = src_tok + ['<EOS>'] + ['<BOS>'] + tgt_tok, index = pred_tok + ['<EOS>'])\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(df,cmap=\"Blues\",square=True,ax=ax_main,cbar=False)#Reds,center=0\n",
    "    src_contribution = contributions_rollout_layer_np[:,:len(src_tok)].sum(-1)\n",
    "    src_contribution\n",
    "    df_src_contribution = pd.DataFrame(src_contribution, columns = ['src_contribution'], index = tgt_tok + ['<EOS>'])\n",
    "    #sns.set_style(\"white\")\n",
    "    ax_yDist.barh(range(0,len(tgt_tok + ['<EOS>'])), df_src_contribution.src_contribution, align='center')\n",
    "    plt.yticks(ticks = range(0,len(tgt_tok + ['<EOS>'])) ,labels = pred_tok + ['<EOS>'],fontsize='14')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(visible=True)\n",
    "    ax_yDist.set_xlim(0,1)\n",
    "\n",
    "    ax_main.set_title('Layer ' + str(layer+1))\n",
    "    ax_yDist.set_title('Source contribution')\n",
    "    #sns.despine(left=True, bottom=True)\n",
    "    ax_yDist.xaxis.set_ticks_position(\"bottom\")\n",
    "    # ax_yDist.xaxis.grid(False)\n",
    "    # ax_yDist.yaxis.grid(False)\n",
    "    #plt.gcf().subplots_adjust(bottom=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,8),dpi=200)\n",
    "# df = pd.DataFrame(contributions_rollout_layer_np, columns = src_tok + ['<EOS>'] + ['<BOS>'] + tgt_tok, index = pred_tok + ['<EOS>'])\n",
    "# sns.set(font_scale=1.6)\n",
    "# sns.heatmap(df,cmap=\"Blues\",square=True,cbar=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-word alignments (source-target) from contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_pred_src = contributions_rollout_layer_np[:,:len(src_tok)+1]\n",
    "src_word_to_bpe = align.convert_bpe_word(src_tok_str, src_word_sent)\n",
    "tgt_word_to_bpe = align.convert_bpe_word(tgt_tok_str, tgt_word_sent)\n",
    "contributions_word_word = align.get_word_word_attention(contribution_pred_src, src_word_to_bpe, tgt_word_to_bpe, remove_EOS=False)\n",
    "contributions_word_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Soft alignment\n",
    "plt.figure(figsize=(20,8))\n",
    "df = pd.DataFrame(contributions_word_word, columns = src_word_sent.split() + ['<EOS>'], index = tgt_word_sent.split() + ['<EOS>'])\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True,cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hard alignment\n",
    "a_argmax = np.argmax(contributions_word_word, -1)\n",
    "contributions_word_word_hard = np.zeros(contributions_word_word.shape)\n",
    "\n",
    "for i, j in enumerate(a_argmax):\n",
    "    contributions_word_word_hard[i][j] = 1\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "df = pd.DataFrame(contributions_word_word_hard, columns = src_word_sent.split() + ['<EOS>'], index = tgt_word_sent.split() + ['<EOS>'])\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(df,cmap=\"Blues\",square=True,cbar=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [\"whitesmoke\", \"gainsboro\", \"lightgrey\", \"lightgray\", \"silver\",\n",
    "            \"darkgrey\", \"darkgray\", \"grey\", \"gray\", \"dimgrey\", \"dimgray\", \"black\"]\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', colors, len(colors))\n",
    "i=3\n",
    "src_word_sent = src_word_sents[i]\n",
    "print(src_word_sent)\n",
    "tgt_word_sent = tgt_word_sents[i]\n",
    "print(tgt_word_sent)\n",
    "\n",
    "attention_matrix = np.zeros((len(tgt_word_sent.split())+1,len(src_word_sent.split())+1))\n",
    "with open(gold_alignment, 'r') as f:\n",
    "    line = f.readlines()[i]\n",
    "    for alignment_string in line.split():\n",
    "        t, s = parse_single_alignment(alignment_string, reverse=True)\n",
    "        attention_matrix[t-1][s-1] = 1\n",
    "#attention_matrix = attention_matrix[[len(attention_matrix)-1]+list(range(0,len(attention_matrix)-1))]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "fontsize = 10\n",
    "rotation = 90\n",
    "df_gold = pd.DataFrame(attention_matrix, columns=src_word_sent.split()+[\"<EOS>\"],index=tgt_word_sent.split()+[\"<EOS>\"])\n",
    "sns.heatmap(df_gold,cmap=cmap,cbar=False,square=True)\n",
    "sns.set(font_scale=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d90d8f5aa2056217711987bb6fa8dc20d62369a1e594ceedbb30cde0480a32e5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
