{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# add reference to the few_shot dir\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp_en = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "lang_tokenizers = {\"en\": nlp_en.tokenizer}\n",
    "tokens = lang_tokenizers[\"en\"](\"This is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks import FEW_SHOT_TASKS_REGISTRY\n",
    "\n",
    "def get_sets_by_lang(sets, lang):\n",
    "    supported_sets = {}\n",
    "    for s, v in sets.items():\n",
    "        if isinstance(v, dict):\n",
    "            if lang not in v:\n",
    "                continue\n",
    "            supported_sets[s] = v[lang] \n",
    "        else:\n",
    "            if lang == \"en\":\n",
    "                supported_sets[s] = v\n",
    "    return supported_sets\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:copa\n",
      "copa train \n",
      "{'premise': 'My body cast a shadow over the grass.', 'choice1': 'The sun was rising.', 'choice2': 'The grass was cut.', 'question': 'cause', 'label': 0, 'idx': 0}\n",
      "copa val \n",
      "{'premise': 'The man turned on the faucet.', 'choice1': 'The toilet filled with water.', 'choice2': 'Water flowed from the spout.', 'question': 'effect', 'label': 1, 'idx': 0}\n",
      "copa test \n",
      "{'premise': 'The item was packaged in bubble wrap.', 'choice1': 'It was fragile.', 'choice2': 'It was small.', 'question': 'cause', 'idx': 0}\n",
      "task:pawsx\n",
      "pawsx dev \n",
      "{'id': '4', 'sentence1': 'From the merger of the Four Rivers Council and the Audubon Council , the Shawnee Trails Council was born .', 'sentence2': 'Shawnee Trails Council was formed from the merger of the Four Rivers Council and the Audubon Council .', 'label': '1'}\n",
      "pawsx test \n",
      "{'id': '10', 'sentence1': 'The exception was between late 2005 and 2009 when he played in Sweden with Carlstad United BK , Serbia with FK Borac Čačak and Russian FC Terek Grozny .', 'sentence2': 'The exception was between late 2005 and 2009 , when he played in Sweden with Carlstad United BK , Serbia with FK Borac Čačak and the Russian FC Terek Grozny .', 'label': '1'}\n",
      "task:hellaswag\n",
      "hellaswag train \n",
      "{'ind': 4, 'activity_label': 'Removing ice from car', 'ctx_a': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles.', 'ctx_b': 'then', 'ctx': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then', 'split': 'train', 'split_type': 'indomain', 'label': 3, 'endings': [', the man adds wax to the windshield and cuts it.', ', a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.', ', the man puts on a christmas coat, knitted with netting.', ', the man continues removing the snow on his car.'], 'source_id': 'activitynet~v_-1IBHYS3L-Y'}\n",
      "hellaswag val \n",
      "{'ind': 24, 'activity_label': 'Roof shingle removal', 'ctx_a': 'A man is sitting on a roof.', 'ctx_b': 'he', 'ctx': 'A man is sitting on a roof. he', 'split': 'val', 'split_type': 'indomain', 'label': 3, 'endings': ['is using wrap to wrap a pair of skis.', 'is ripping level tiles off.', \"is holding a rubik's cube.\", 'starts pulling up roofing on a roof.'], 'source_id': 'activitynet~v_-JhWjGDPHMY'}\n",
      "hellaswag test \n",
      "{'ind': 14, 'activity_label': 'Wakeboarding', 'ctx_a': 'A man is being pulled on a water ski as he floats in the water casually.', 'ctx_b': 'he', 'ctx': 'A man is being pulled on a water ski as he floats in the water casually. he', 'split': 'test', 'split_type': 'indomain', 'endings': ['mounts the water ski and tears through the water at fast speeds.', 'goes over several speeds, trying to stay upright.', 'struggles a little bit as he talks about it.', 'is seated in a boat with three other people.'], 'source_id': 'activitynet~v_-5KAycAQlC4'}\n",
      "task:storycloze\n",
      "storycloze val2016 \n",
      "{'InputStoryid': '138d5bfb-05cc-41e3-bf2c-fa85ebad14e2', 'InputSentence1': 'Rick grew up in a troubled household.', 'InputSentence2': 'He never found good support in family, and turned to gangs.', 'InputSentence3': \"It wasn't long before Rick got shot in a robbery.\", 'InputSentence4': 'The incident caused him to turn a new leaf.', 'RandomFifthSentenceQuiz1': 'He is happy now.', 'RandomFifthSentenceQuiz2': 'He joined a gang.', 'AnswerRightEnding': '1'}\n",
      "storycloze test2016 \n",
      "{'InputStoryid': 'b929f263-1dcd-4a0b-b267-5d5ff2fe65bb', 'InputSentence1': 'My friends all love to go to the club to dance.', 'InputSentence2': \"They think it's a lot of fun and always invite.\", 'InputSentence3': 'I finally decided to tag along last Saturday.', 'InputSentence4': \"I danced terribly and broke a friend's toe.\", 'RandomFifthSentenceQuiz1': 'My friends decided to keep inviting me out as I am so much fun.', 'RandomFifthSentenceQuiz2': 'The next weekend, I was asked to please stay home.', 'AnswerRightEnding': '2'}\n",
      "storycloze val2018 \n",
      "{'InputStoryid': '138d5bfb-05cc-41e3-bf2c-fa85ebad14e2', 'InputSentence1': 'Rick grew up in a troubled household.', 'InputSentence2': 'He never found good support in family, and turned to gangs.', 'InputSentence3': \"It wasn't long before Rick got shot in a robbery.\", 'InputSentence4': 'The incident caused him to turn a new leaf.', 'RandomFifthSentenceQuiz1': 'He is happy now.', 'RandomFifthSentenceQuiz2': 'He joined a gang.', 'AnswerRightEnding': '1'}\n",
      "storycloze test2018 \n",
      "{'InputStoryid': 'f6aad64a-e34c-415d-b895-dbfa187ed43e', 'InputSentence1': 'Bob was bored at his job as a school teacher.', 'InputSentence2': 'He had been working so hard this past month.', 'InputSentence3': 'He decided to treat himself with something special.', 'InputSentence4': 'He ordered tickets for a weekend snowboarding trip.', 'RandomFifthSentenceQuiz1': 'He was looking forward to getting away.', 'RandomFifthSentenceQuiz2': 'His boss told him he had to work this weekend.'}\n",
      "task:winograd\n",
      "winograd test \n",
      "{'txt1': 'The city councilmen refused the demonstrators a permit because', 'txt2': 'feared violence.', 'pron': 'they', 'candidates': ['The city councilmen', 'The demonstrators'], 'correct_candidates': ['The city councilmen']}\n",
      "task:piqa\n",
      "piqa train \n",
      "{'goal': \"When boiling butter, when it's ready, you can\", 'sol1': 'Pour it onto a plate', 'sol2': 'Pour it into a jar', 'label': 1}\n",
      "piqa valid \n",
      "{'goal': \"How do I ready a guinea pig cage for it's new occupants?\", 'sol1': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.', 'sol2': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.', 'label': 0}\n",
      "piqa test \n",
      "{'goal': 'how do you puncture a vein?', 'sol1': 'hit it at the wrong angle and make it bleed.', 'sol2': 'pop it.', 'label': 0}\n",
      "task:openbookqa\n",
      "openbookqa train \n",
      "{'id': '7-980', 'question': {'stem': 'The sun is responsible for', 'choices': [{'text': 'puppies learning new tricks', 'label': 'A'}, {'text': 'children growing up and getting old', 'label': 'B'}, {'text': 'flowers wilting in a vase', 'label': 'C'}, {'text': 'plants sprouting, blooming and wilting', 'label': 'D'}]}, 'answerKey': 'D'}\n",
      "openbookqa dev \n",
      "{'id': '8-376', 'question': {'stem': 'Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as', 'choices': [{'text': 'Deep sea animals', 'label': 'A'}, {'text': 'fish', 'label': 'B'}, {'text': 'Long Sea Fish', 'label': 'C'}, {'text': 'Far Sea Animals', 'label': 'D'}]}, 'answerKey': 'A'}\n",
      "openbookqa test \n",
      "{'id': '8-343', 'question': {'stem': 'A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to', 'choices': [{'text': 'make more phone calls', 'label': 'A'}, {'text': 'quit eating lunch out', 'label': 'B'}, {'text': 'buy less with monopoly money', 'label': 'C'}, {'text': 'have lunch with friends', 'label': 'D'}]}, 'answerKey': 'B'}\n",
      "task:xnli\n",
      "xnli dev \n",
      "{'annotator_labels': ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral'], 'genre': 'facetoface', 'gold_label': 'neutral', 'language': 'en', 'match': 'True', 'pairID': '1', 'promptID': '1', 'sentence1': \"And he said, Mama, I'm home.\", 'sentence1_tokenized': \"And he said , Mama , I 'm home .\", 'sentence2': 'He called his mom as soon as the school bus dropped him off.', 'sentence2_tokenized': 'He called his mom as soon as the school bus dropped him off .'}\n",
      "xnli test \n",
      "{'annotator_labels': ['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction'], 'genre': 'facetoface', 'gold_label': 'contradiction', 'language': 'en', 'match': 'True', 'pairID': '4', 'promptID': '2', 'sentence1': \"Well, I wasn't even thinking about that, but I was so frustrated, and, I ended up talking to him again.\", 'sentence1_tokenized': \"Well , I wasn 't even thinking about that , but I was so frustrated , and , I ended up talking to him again .\", 'sentence2': 'I havent spoken to him again.', 'sentence2_tokenized': 'I havent spoken to him again .'}\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "#XCOPA\tXNLI\tPAWS-X\tmLAMA\tStoryCloze\tHellaswag\tReCoRD\tPIQA\n",
    "tasks = [\n",
    "         \"copa\", \"xnli\", \"pawsx\", \"storycloze\", \n",
    "         \"hellaswag\", \n",
    "         #\"record\", \n",
    "         \"piqa\", \n",
    "         \"openbookqa\",\n",
    "         \"winograd\"\n",
    "        ]\n",
    "#tasks = [\"winograd\"]\n",
    "langs_mapping = {\"any\":\"en\"}\n",
    "task_instance_to_str = {\n",
    "    \"winograd\": lambda item: \" \".join([item[c] for c in ['goal', 'sol1', 'sol2']]),\n",
    "    # task: lambda item: \" \".join([item[c] for c in ['', '', '']]),\n",
    "    \"copa\": lambda item: \" \".join([item[c] for c in ['premise', 'choice1', 'choice2']]),\n",
    "    \"xnli\": lambda item: \" \".join([item[c] for c in ['sentence1', 'sentence2']]),\n",
    "    \"pawsx\":  lambda item: \" \".join([item[c] for c in ['sentence1', 'sentence2']]),\n",
    "    \"storycloze\": lambda item: \" \".join([item[c] for c in ['InputSentence1', 'InputSentence2', 'InputSentence3', 'InputSentence4', 'RandomFifthSentenceQuiz1', 'RandomFifthSentenceQuiz2']]), \n",
    "    \"hellaswag\": lambda item: \" \".join([item[\"ctx\"]] + item[\"endings\"]),\n",
    "    #\"record\":[], \n",
    "    \"winograd\": lambda item: \" \".join([item[\"txt1\"]] + [x + \" \"  +item[\"txt2\"] for x in item[\"candidates\"]]),\n",
    "    \"piqa\": lambda item: \" \".join([item[c] for c in ['goal', 'sol1', 'sol2']]),\n",
    "    \"openbookqa\": lambda item: \"\\n\".join([item[\"question\"][\"stem\"]] + [ch[\"label\"] + \") \" + ch[\"text\"]  for ch in item[\"question\"][\"choices\"]]),\n",
    "}\n",
    "\n",
    "def get_token_info(items, task, lang):\n",
    "    stringify = task_instance_to_str[task]\n",
    "    tokenizer = lang_tokenizers[lang]\n",
    "    items_tokens_cnt = [] \n",
    "    for item in items:\n",
    "        item_str = stringify(item)\n",
    "        item_tokens = tokenizer(item_str)\n",
    "        items_tokens_cnt.append(len(item_tokens))\n",
    "        \n",
    "    return {\n",
    "        \"items\": len(items_tokens_cnt),\n",
    "        \"total_tokens\": sum(items_tokens_cnt),\n",
    "        \"tokens_per_item\": sum(items_tokens_cnt)/len(items_tokens_cnt),\n",
    "    }\n",
    "    \n",
    "    \n",
    "for t, task_class in FEW_SHOT_TASKS_REGISTRY.items():\n",
    "    if t not in tasks:\n",
    "        continue\n",
    "    print(f\"task:{t}\")\n",
    "    task_langs = langs_mapping.get(t, [langs_mapping[\"any\"]])\n",
    "    #task_fields = fields[t]\n",
    "    \n",
    "    set_to_file_mapping = task_class.get_sets_and_lang_to_path_mappings()\n",
    "#     if t == \"pawsx\":\n",
    "#         print(set_to_file_mapping)\n",
    "        \n",
    "    for lang in task_langs:\n",
    "        lang_sets = get_sets_by_lang(set_to_file_mapping, lang)\n",
    "        #print(f\"{lang} {lang_sets}\")\n",
    "        for s, p in lang_sets.items():\n",
    "            set_info = {\n",
    "                \"task\": t,\n",
    "                \"lang\": lang,\n",
    "                \"set\": s,\n",
    "            }\n",
    "            if p is None:\n",
    "                #print(t, s, p)\n",
    "                continue\n",
    "            set_path = str(p)\n",
    "            task_instance = task_class.from_kwargs(**{\"language\": lang})\n",
    "            task_items = task_instance.read_data(set_path)\n",
    "            print(f\"{t} {s} \")\n",
    "            print(task_items[0])\n",
    "            token_info = get_token_info(task_items, t, lang)\n",
    "            \n",
    "            set_info.update(token_info)\n",
    "            \n",
    "            values.append(set_info)\n",
    "            \n",
    "            \n",
    "            \n",
    "    # break # debug\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>lang</th>\n",
       "      <th>set</th>\n",
       "      <th>items</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>tokens_per_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>copa</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>400</td>\n",
       "      <td>7849</td>\n",
       "      <td>19.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>copa</td>\n",
       "      <td>en</td>\n",
       "      <td>val</td>\n",
       "      <td>100</td>\n",
       "      <td>2005</td>\n",
       "      <td>20.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>copa</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>500</td>\n",
       "      <td>9620</td>\n",
       "      <td>19.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pawsx</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2000</td>\n",
       "      <td>86219</td>\n",
       "      <td>43.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pawsx</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2000</td>\n",
       "      <td>86982</td>\n",
       "      <td>43.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>39905</td>\n",
       "      <td>6498519</td>\n",
       "      <td>162.849743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>en</td>\n",
       "      <td>val</td>\n",
       "      <td>10042</td>\n",
       "      <td>1695358</td>\n",
       "      <td>168.826728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>10003</td>\n",
       "      <td>1646345</td>\n",
       "      <td>164.585124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>storycloze</td>\n",
       "      <td>en</td>\n",
       "      <td>val2016</td>\n",
       "      <td>1871</td>\n",
       "      <td>107514</td>\n",
       "      <td>57.463389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>storycloze</td>\n",
       "      <td>en</td>\n",
       "      <td>test2016</td>\n",
       "      <td>1871</td>\n",
       "      <td>107569</td>\n",
       "      <td>57.492785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>storycloze</td>\n",
       "      <td>en</td>\n",
       "      <td>val2018</td>\n",
       "      <td>1571</td>\n",
       "      <td>90223</td>\n",
       "      <td>57.430299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>storycloze</td>\n",
       "      <td>en</td>\n",
       "      <td>test2018</td>\n",
       "      <td>1571</td>\n",
       "      <td>93414</td>\n",
       "      <td>59.461489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>winograd</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>273</td>\n",
       "      <td>7135</td>\n",
       "      <td>26.135531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>piqa</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>16113</td>\n",
       "      <td>813131</td>\n",
       "      <td>50.464283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>piqa</td>\n",
       "      <td>en</td>\n",
       "      <td>valid</td>\n",
       "      <td>1838</td>\n",
       "      <td>91740</td>\n",
       "      <td>49.912949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>piqa</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>3084</td>\n",
       "      <td>150740</td>\n",
       "      <td>48.878080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>openbookqa</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>4957</td>\n",
       "      <td>172386</td>\n",
       "      <td>34.776276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>openbookqa</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>500</td>\n",
       "      <td>18316</td>\n",
       "      <td>36.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>openbookqa</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>500</td>\n",
       "      <td>17767</td>\n",
       "      <td>35.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xnli</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2490</td>\n",
       "      <td>79035</td>\n",
       "      <td>31.740964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xnli</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>5010</td>\n",
       "      <td>159300</td>\n",
       "      <td>31.796407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          task lang       set  items  total_tokens  tokens_per_item\n",
       "0         copa   en     train    400          7849        19.622500\n",
       "1         copa   en       val    100          2005        20.050000\n",
       "2         copa   en      test    500          9620        19.240000\n",
       "3        pawsx   en       dev   2000         86219        43.109500\n",
       "4        pawsx   en      test   2000         86982        43.491000\n",
       "5    hellaswag   en     train  39905       6498519       162.849743\n",
       "6    hellaswag   en       val  10042       1695358       168.826728\n",
       "7    hellaswag   en      test  10003       1646345       164.585124\n",
       "8   storycloze   en   val2016   1871        107514        57.463389\n",
       "9   storycloze   en  test2016   1871        107569        57.492785\n",
       "10  storycloze   en   val2018   1571         90223        57.430299\n",
       "11  storycloze   en  test2018   1571         93414        59.461489\n",
       "12    winograd   en      test    273          7135        26.135531\n",
       "13        piqa   en     train  16113        813131        50.464283\n",
       "14        piqa   en     valid   1838         91740        49.912949\n",
       "15        piqa   en      test   3084        150740        48.878080\n",
       "16  openbookqa   en     train   4957        172386        34.776276\n",
       "17  openbookqa   en       dev    500         18316        36.632000\n",
       "18  openbookqa   en      test    500         17767        35.534000\n",
       "19        xnli   en       dev   2490         79035        31.740964\n",
       "20        xnli   en      test   5010        159300        31.796407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(values)\n",
    "df.to_csv('tokens_info.tsv',sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairseq-20210102",
   "language": "python",
   "name": "fairseq-20210102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
